{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165166dd",
   "metadata": {},
   "source": [
    "# DS Automation Assignment - Courtney Drysdale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195af74",
   "metadata": {},
   "source": [
    "Using our prepared churn data from week 2:\n",
    "- use pycaret to find an ML algorithm that performs best on the data\n",
    "    - Choose a metric you think is best to use for finding the best model; by default, it is accuracy but it could be AUC, precision, recall, etc. The week 3 FTE has some information on these different metrics.\n",
    "- save the model to disk\n",
    "- create a Python script/file/module with a function that takes a pandas dataframe as an input and returns the probability of churn for each row in the dataframe\n",
    "    - your Python file/function should print out the predictions for new data (new_churn_data.csv)\n",
    "    - the true values for the new data are [1, 0, 0, 1, 0] if you're interested\n",
    "- test your Python module and function with the new data, new_churn_data.csv\n",
    "- write a short summary of the process and results at the end of this notebook\n",
    "- upload this Jupyter Notebook and Python file to a Github repository, and turn in a link to the repository in the week 5 assignment dropbox\n",
    "\n",
    "*Optional* challenges:\n",
    "- return the probability of churn for each new prediction, and the percentile where that prediction is in the distribution of probability predictions from the training dataset (e.g. a high probability of churn like 0.78 might be at the 90th percentile)\n",
    "- use other autoML packages, such as TPOT, H2O, MLBox, etc, and compare performance and features with pycaret\n",
    "- create a class in your Python module to hold the functions that you created\n",
    "- accept user input to specify a file using a tool such as Python's `input()` function, the `click` package for command-line arguments, or a GUI\n",
    "- Use the unmodified churn data (new_unmodified_churn_data.csv) in your Python script. This will require adding the same preprocessing steps from week 2 since this data is like the original unmodified dataset from week 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "476ed965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae16db16-45a3-42d0-8574-d991c7978ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>TotalChargesTenureRatio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7590-VHVEG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>29.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575-GNVDE</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>55.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668-QPYBK</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>54.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795-CFOCW</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>40.905556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237-HQITU</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>75.825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  PhoneService  Contract  PaymentMethod  MonthlyCharges  \\\n",
       "customerID                                                                  \n",
       "7590-VHVEG       1             0         0              1           29.85   \n",
       "5575-GNVDE      34             1         1              0           56.95   \n",
       "3668-QPYBK       2             1         0              0           53.85   \n",
       "7795-CFOCW      45             0         1              2           42.30   \n",
       "9237-HQITU       2             1         0              1           70.70   \n",
       "\n",
       "            TotalCharges  Churn  TotalChargesTenureRatio  \n",
       "customerID                                                \n",
       "7590-VHVEG         29.85      0                29.850000  \n",
       "5575-GNVDE       1889.50      0                55.573529  \n",
       "3668-QPYBK        108.15      1                54.075000  \n",
       "7795-CFOCW       1840.75      0                40.905556  \n",
       "9237-HQITU        151.65      1                75.825000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('prepped_churn_data.csv', index_col='customerID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd97954c-07c4-4fdc-9250-fff454ecfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Churn', axis=1)\n",
    "targets = df['Churn']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, targets, stratify=targets, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2036a901-0556-47e9-a5fd-b05c6b5ed507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7963592542964288\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7963592542964288\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.797306761873072\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7993924296518791\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7993924296518791\n",
      "\n",
      "Best pipeline: XGBClassifier(MultinomialNB(MinMaxScaler(input_matrix), alpha=1.0, fit_prior=True), learning_rate=0.1, max_depth=1, min_child_weight=13, n_estimators=100, n_jobs=1, subsample=0.3, verbosity=0)\n",
      "0.7849829351535836\n",
      "CPU times: user 1min 10s, sys: 12.5 s, total: 1min 23s\n",
      "Wall time: 9min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/courtney/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:780: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, cv=5,random_state=42, scoring='accuracy', verbosity=2, n_jobs=-1)\n",
    "\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb696fb-6647-4e03-a258-3370c91e2560",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "I have tried multiple ways to clear this future warning, and I am not able to do it. I have updated sklearn, tried to find other ways to score, imported other packages, and I am at a loss for what to do. I also tried to learn how to ignore a warning in a single cell, but I didn't want to mess up anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38be1903-5e68-4340-9ea5-5fa363e357d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the TPOT predictions: 0.7849829351535836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Accuracy of the TPOT predictions: {accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66f4077d-a87f-4af2-b44d-e4369fcfc64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_churn_pipeline5.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "834cf013-b6c9-413d-a90d-f5fc5b056a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.naive_bayes</span> <span class=\"kn\">import</span> <span class=\"n\">MultinomialNB</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">make_pipeline</span><span class=\"p\">,</span> <span class=\"n\">make_union</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">sklearn.preprocessing</span> <span class=\"kn\">import</span> <span class=\"n\">MinMaxScaler</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.builtins</span> <span class=\"kn\">import</span> <span class=\"n\">StackingEstimator</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">xgboost</span> <span class=\"kn\">import</span> <span class=\"n\">XGBClassifier</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">tpot.export_utils</span> <span class=\"kn\">import</span> <span class=\"n\">set_param_recursive</span>\n",
       "\n",
       "<span class=\"c1\"># NOTE: Make sure that the outcome column is labeled &#39;target&#39; in the data file</span>\n",
       "<span class=\"n\">tpot_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">&#39;prepped_churn_data.csv&#39;</span><span class=\"p\">,</span> <span class=\"n\">index_col</span><span class=\"o\">=</span><span class=\"s1\">&#39;customerID&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">tpot_data</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">testing_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">,</span> <span class=\"n\">testing_target</span> <span class=\"o\">=</span> \\\n",
       "            <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"p\">,</span> <span class=\"n\">tpot_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;Churn&#39;</span><span class=\"p\">],</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Average CV score on the training set was: 0.7993924296518791</span>\n",
       "<span class=\"n\">exported_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">make_pipeline</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">MinMaxScaler</span><span class=\"p\">(),</span>\n",
       "    <span class=\"n\">StackingEstimator</span><span class=\"p\">(</span><span class=\"n\">estimator</span><span class=\"o\">=</span><span class=\"n\">MultinomialNB</span><span class=\"p\">(</span><span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"n\">fit_prior</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)),</span>\n",
       "    <span class=\"n\">XGBClassifier</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">min_child_weight</span><span class=\"o\">=</span><span class=\"mi\">13</span><span class=\"p\">,</span> <span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">subsample</span><span class=\"o\">=</span><span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"n\">verbosity</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"c1\"># Fix random state for all the steps in exported pipeline</span>\n",
       "<span class=\"n\">set_param_recursive</span><span class=\"p\">(</span><span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">steps</span><span class=\"p\">,</span> <span class=\"s1\">&#39;random_state&#39;</span><span class=\"p\">,</span> <span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">training_features</span><span class=\"p\">,</span> <span class=\"n\">training_target</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">exported_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">testing_features</span><span class=\"p\">)</span>\n",
       "<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{numpy} \\PY{k}{as} \\PY{n+nn}{np}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{model\\PYZus{}selection} \\PY{k+kn}{import} \\PY{n}{train\\PYZus{}test\\PYZus{}split}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{naive\\PYZus{}bayes} \\PY{k+kn}{import} \\PY{n}{MultinomialNB}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{pipeline} \\PY{k+kn}{import} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{,} \\PY{n}{make\\PYZus{}union}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{sklearn}\\PY{n+nn}{.}\\PY{n+nn}{preprocessing} \\PY{k+kn}{import} \\PY{n}{MinMaxScaler}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{builtins} \\PY{k+kn}{import} \\PY{n}{StackingEstimator}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{xgboost} \\PY{k+kn}{import} \\PY{n}{XGBClassifier}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{tpot}\\PY{n+nn}{.}\\PY{n+nn}{export\\PYZus{}utils} \\PY{k+kn}{import} \\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} NOTE: Make sure that the outcome column is labeled \\PYZsq{}target\\PYZsq{} in the data file}\n",
       "\\PY{n}{tpot\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{read\\PYZus{}csv}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{prepped\\PYZus{}churn\\PYZus{}data.csv}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{index\\PYZus{}col}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{customerID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{n}{features} \\PY{o}{=} \\PY{n}{tpot\\PYZus{}data}\\PY{o}{.}\\PY{n}{drop}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{axis}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{testing\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{,} \\PY{n}{testing\\PYZus{}target} \\PY{o}{=} \\PYZbs{}\n",
       "            \\PY{n}{train\\PYZus{}test\\PYZus{}split}\\PY{p}{(}\\PY{n}{features}\\PY{p}{,} \\PY{n}{tpot\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Churn}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Average CV score on the training set was: 0.7993924296518791}\n",
       "\\PY{n}{exported\\PYZus{}pipeline} \\PY{o}{=} \\PY{n}{make\\PYZus{}pipeline}\\PY{p}{(}\n",
       "    \\PY{n}{MinMaxScaler}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{StackingEstimator}\\PY{p}{(}\\PY{n}{estimator}\\PY{o}{=}\\PY{n}{MultinomialNB}\\PY{p}{(}\\PY{n}{alpha}\\PY{o}{=}\\PY{l+m+mf}{1.0}\\PY{p}{,} \\PY{n}{fit\\PYZus{}prior}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{n}{XGBClassifier}\\PY{p}{(}\\PY{n}{learning\\PYZus{}rate}\\PY{o}{=}\\PY{l+m+mf}{0.1}\\PY{p}{,} \\PY{n}{max\\PYZus{}depth}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{min\\PYZus{}child\\PYZus{}weight}\\PY{o}{=}\\PY{l+m+mi}{13}\\PY{p}{,} \\PY{n}{n\\PYZus{}estimators}\\PY{o}{=}\\PY{l+m+mi}{100}\\PY{p}{,} \\PY{n}{n\\PYZus{}jobs}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{subsample}\\PY{o}{=}\\PY{l+m+mf}{0.3}\\PY{p}{,} \\PY{n}{verbosity}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "\\PY{p}{)}\n",
       "\\PY{c+c1}{\\PYZsh{} Fix random state for all the steps in exported pipeline}\n",
       "\\PY{n}{set\\PYZus{}param\\PYZus{}recursive}\\PY{p}{(}\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{steps}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{random\\PYZus{}state}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+m+mi}{42}\\PY{p}{)}\n",
       "\n",
       "\\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{training\\PYZus{}features}\\PY{p}{,} \\PY{n}{training\\PYZus{}target}\\PY{p}{)}\n",
       "\\PY{n}{results} \\PY{o}{=} \\PY{n}{exported\\PYZus{}pipeline}\\PY{o}{.}\\PY{n}{predict}\\PY{p}{(}\\PY{n}{testing\\PYZus{}features}\\PY{p}{)}\n",
       "\\PY{n+nb}{print}\\PY{p}{(}\\PY{n}{results}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.naive_bayes import MultinomialNB\n",
       "from sklearn.pipeline import make_pipeline, make_union\n",
       "from sklearn.preprocessing import MinMaxScaler\n",
       "from tpot.builtins import StackingEstimator\n",
       "from xgboost import XGBClassifier\n",
       "from tpot.export_utils import set_param_recursive\n",
       "\n",
       "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
       "tpot_data = pd.read_csv('prepped_churn_data.csv', index_col='customerID')\n",
       "features = tpot_data.drop('Churn', axis=1)\n",
       "training_features, testing_features, training_target, testing_target = \\\n",
       "            train_test_split(features, tpot_data['Churn'], random_state=42)\n",
       "\n",
       "# Average CV score on the training set was: 0.7993924296518791\n",
       "exported_pipeline = make_pipeline(\n",
       "    MinMaxScaler(),\n",
       "    StackingEstimator(estimator=MultinomialNB(alpha=1.0, fit_prior=True)),\n",
       "    XGBClassifier(learning_rate=0.1, max_depth=1, min_child_weight=13, n_estimators=100, n_jobs=1, subsample=0.3, verbosity=0)\n",
       ")\n",
       "# Fix random state for all the steps in exported pipeline\n",
       "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
       "\n",
       "exported_pipeline.fit(training_features, training_target)\n",
       "results = exported_pipeline.predict(testing_features)\n",
       "print(results)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "Code('tpot_churn_pipeline5_filledin.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd95db1-4639-4c74-958c-ce298c4c1046",
   "metadata": {},
   "source": [
    "## Running Python File\n",
    "\n",
    "This one had me confused with trying to convert the customerID from a string to a float, but then I realized I could add the index_col parameter to the read_csv function and it worked. I printed the results below but due to the size of the dataset it is only printing the first and last three results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af618acf-8703-444c-99c9-49029a283332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "%run tpot_churn_pipeline5_filledin.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49db562",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533a1cd",
   "metadata": {},
   "source": [
    "The prepped data was imported, split into test and train sets, then fit to a TPOT model. The TPOT ran 5 generations and found that the best pipeline was XGBClassifier. The TPOT was exported to a python file, which I then updated with the correct file path and target column name and ran it again on the prepped data. The TPOT accuracy was 78% which is better than the \"no information\" rate we looked at earlier in the data analysis. And the average score on the training set was 80% for the selected model, XGBClassifier. Overall, comparing to the other models that we have tried in recent weeks, the performance is about the same as other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
